\section{Testing on Physical Hardware (2 pages)}

The first phase of this testing is to port the high-performing networks from testing in simulation to the real hardware.
So far, we are targeting our existing Google Coral Dev Board, which has an embedded TPU,
and an NVIDIA Jetson Nano, which has an embedded GPU.
We will implement the pre-/post-processing wrappers for rectification and command generation in the same way as in the testing in simulation,
and instantiate the trained networks on the embedded hardware.
We can then pipe data from the synthetic or real-world data sets into the physical system
to collect empirical results
for the framerate achieved and power/computational requirements in making predictions
using the networks.
Piping data to the system will allow us to test the hardware/software in isolation,
such that the effect of installing it onto our drone systems will be predictable.
This is an area where we may have to carefully re-consider purchasing new embedded computational
hardware, if none of the networks run fast enough, or if they all take too much power.
Aside from the Google Coral and Jetson Nano, we will also consider some FPGA in the future.

If any of the combinations of networks and hardware work with enough accuracy,
at a high enough framerate, and by consuming little enough power,
we will install this hardware onto a physical drone and test the system in a real
autonomous landing scenario.